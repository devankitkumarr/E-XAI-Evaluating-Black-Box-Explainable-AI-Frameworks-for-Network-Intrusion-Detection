# E-XAI-Evaluating-Black-Box-Explainable-AI-Frameworks-for-Network-Intrusion-Detection
 E-XAI (Explainable AI (XAI)) methods in intrusion detection systems (IDS). Global and lo
cal explanation techniques, including LIME and SHAP, are applied to
 multiple IDS models trained on three datasets: SIMARGL 2021, NSL
KDD, and CICIDS 2017. The integrated XAI methods enhance trans
parency and trust in model decisions. Experimental results show the Vot
ing Classifier (boosted decision trees + bagging random forests) achieves
 top accuracy: 97.9% on CICIDS 2017, 99.4% on NSL-KDD, and 100%
 on SIMARGL 2021. The results confirm the frameworkâ€™s effectiveness in
 combining high detection performance with interpretability.
 XAI, intrusion detection, SHAP, LIME, network security, black-box
 models, NSL-KDD, CICIDS-2017, SIMARGL 2021
